{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'input_data'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-08210647586a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'input_data'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# def model(X_train, Y_train, X_test, Y_test, learning_rate=0.01, num_iterations=1000, print_cost=True):\n",
    "#     ops.reset_default_graph()\n",
    "#     \n",
    "#     # seed = 3\n",
    "#     (n_x, m) = X_train.shape\n",
    "#     n_y = Y_train.shape[0]\n",
    "#     costs = []\n",
    "#     \n",
    "#     X, Y = create_placeholders(n_x, n_y)\n",
    "#     \n",
    "#     parameters = initialize_parameters()\n",
    "#     \n",
    "#     Z4 = forward_propagation(X, parameters)\n",
    "#     \n",
    "#     cost = compute_cost(Z4, Y)\n",
    "#     \n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#     # optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#     \n",
    "#     init = tf.global_variables_initializer()\n",
    "#     \n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(init)\n",
    "#         # print(\"Init\")\n",
    "#         for i in range(num_iterations):\n",
    "#             _, iter_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "#             \n",
    "#             # Print the cost every 100 training example\n",
    "#             if print_cost and i % 100 == 0:\n",
    "#                 print(\"Cost after iteration {}: {}\".format(i, np.squeeze(iter_cost)))\n",
    "#                 costs.append(iter_cost)\n",
    "#                 \n",
    "#         plt.plot(np.squeeze(costs))\n",
    "#         plt.ylabel('cost')\n",
    "#         plt.xlabel('iterations (per tens)')\n",
    "#         plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "#         plt.show()\n",
    "#         \n",
    "#         parameters = sess.run(parameters)\n",
    "#         print(\"Parameters have been trained!\")\n",
    "#         \n",
    "#         correct_prediction = tf.equal(tf.argmax(Z4), tf.argmax(Y))\n",
    "#         \n",
    "#         accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "#         print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "#         print(\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "#         \n",
    "#         return parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}